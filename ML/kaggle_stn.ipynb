{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.loadtxt('pp_train_x.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.loadtxt('train_y.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.loadtxt('pp_test_x.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "import torchvision.utils as vutils\n",
    "from network import Network\n",
    "import config as cfg\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Mode: stn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training torch.Size([45000, 1, 64, 64]) torch.Size([45000])\n",
      "Testing torch.Size([5000, 1, 64, 64]) torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "def calc_acc(x, y):\n",
    "    x = torch.max(x, dim=-1)[1]\n",
    "    accuracy = sum(x == y) / x.size(0)\n",
    "    return accuracy\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info('Mode: %s' % cfg.mode)\n",
    "if not os.path.exists(cfg.model_dir):\n",
    "    os.mkdir(cfg.model_dir)\n",
    "if not os.path.exists(cfg.transform_img_dir):\n",
    "    os.mkdir(cfg.transform_img_dir)\n",
    "\n",
    "net = Network(mode=cfg.mode)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda(cfg.cuda_num)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=cfg.LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "def to_torch_format(img, target, data_type=''):\n",
    "    '''\n",
    "    :param img: (b, l)\n",
    "    :param target: (b, 1)\n",
    "    :param data_type: string\n",
    "    :return: (b, c, h, w), (b)\n",
    "    '''\n",
    "    batch_size = img.size(0)\n",
    "    img = img.view(batch_size, cfg.channel, cfg.height, cfg.width)\n",
    "    target = target.view(batch_size)\n",
    "    print(data_type, img.size(), target.size())\n",
    "    return img, target\n",
    "\n",
    "t_X = train_x[:45000]\n",
    "t_y = train_y[:45000]\n",
    "\n",
    "v_X = train_x[-5000:]\n",
    "v_y = train_y[-5000:]\n",
    "\n",
    "X_train = torch.from_numpy(t_X).float()\n",
    "y_train = torch.from_numpy(t_y).long()\n",
    "\n",
    "X_test = torch.from_numpy(v_X).float()\n",
    "y_test = torch.from_numpy(v_y).long()\n",
    "\n",
    "X_train, y_train = to_torch_format(X_train, y_train, data_type='Training')\n",
    "X_test, y_test = to_torch_format(X_test, y_test, data_type='Testing')\n",
    "\n",
    "train_dataset = data.TensorDataset(data_tensor=X_train, target_tensor=y_train)\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=cfg.train_batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = data.TensorDataset(data_tensor=X_test, target_tensor=y_test)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=cfg.test_batch_size)\n",
    "\n",
    "train_batch_nb = len(train_loader)\n",
    "test_batch_nb = len(test_loader)\n",
    "\n",
    "\n",
    "# train_dataset = data.TensorDataset(data_tensor=train_x, target_tensor=np.array(map(lambda y: str(y),train_y)))\n",
    "# test_dataset = data.TensorDataset(data_tensor=X_test, target_tensor=y_test)\n",
    "# train_loader = data.DataLoader(dataset=train_dataset, batch_size=cfg.train_batch_size, shuffle=True)\n",
    "# test_loader = data.DataLoader(dataset=test_dataset, batch_size=cfg.test_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:========= Testing: epoch[0/200] loss:0.4094 acc:0.8918\n",
      "INFO:root:========= Testing: epoch[1/200] loss:0.3448 acc:0.9086\n",
      "INFO:root:========= Testing: epoch[2/200] loss:0.3187 acc:0.9170\n",
      "INFO:root:========= Testing: epoch[3/200] loss:0.2986 acc:0.9215\n",
      "INFO:root:========= Testing: epoch[4/200] loss:0.2844 acc:0.9283\n",
      "INFO:root:========= Testing: epoch[5/200] loss:0.2666 acc:0.9307\n",
      "INFO:root:========= Testing: epoch[6/200] loss:0.2679 acc:0.9279\n",
      "INFO:root:========= Testing: epoch[7/200] loss:0.2591 acc:0.9328\n",
      "INFO:root:========= Testing: epoch[8/200] loss:0.2565 acc:0.9326\n",
      "INFO:root:========= Testing: epoch[9/200] loss:0.2517 acc:0.9350\n",
      "INFO:root:========= Testing: epoch[10/200] loss:0.2409 acc:0.9369\n",
      "INFO:root:========= Testing: epoch[11/200] loss:0.2394 acc:0.9404\n",
      "INFO:root:========= Testing: epoch[12/200] loss:0.2426 acc:0.9373\n",
      "INFO:root:========= Testing: epoch[13/200] loss:0.2322 acc:0.9377\n",
      "INFO:root:========= Testing: epoch[14/200] loss:0.2291 acc:0.9400\n",
      "INFO:root:========= Testing: epoch[15/200] loss:0.2395 acc:0.9365\n",
      "INFO:root:========= Testing: epoch[16/200] loss:0.2403 acc:0.9396\n",
      "INFO:root:========= Testing: epoch[17/200] loss:0.2359 acc:0.9408\n",
      "INFO:root:========= Testing: epoch[18/200] loss:0.2338 acc:0.9410\n",
      "INFO:root:========= Testing: epoch[19/200] loss:0.2198 acc:0.9416\n",
      "INFO:root:========= Testing: epoch[20/200] loss:0.2311 acc:0.9393\n",
      "INFO:root:========= Testing: epoch[21/200] loss:0.2218 acc:0.9426\n",
      "INFO:root:========= Testing: epoch[22/200] loss:0.2283 acc:0.9406\n",
      "INFO:root:========= Testing: epoch[23/200] loss:0.2268 acc:0.9402\n",
      "INFO:root:========= Testing: epoch[24/200] loss:0.2321 acc:0.9396\n",
      "INFO:root:========= Testing: epoch[25/200] loss:0.2293 acc:0.9414\n",
      "INFO:root:========= Testing: epoch[26/200] loss:0.2256 acc:0.9436\n",
      "INFO:root:========= Testing: epoch[27/200] loss:0.2255 acc:0.9424\n",
      "INFO:root:========= Testing: epoch[28/200] loss:0.2295 acc:0.9402\n",
      "INFO:root:========= Testing: epoch[29/200] loss:0.2321 acc:0.9412\n",
      "INFO:root:========= Testing: epoch[30/200] loss:0.2101 acc:0.9467\n",
      "INFO:root:========= Testing: epoch[31/200] loss:0.2172 acc:0.9445\n",
      "INFO:root:========= Testing: epoch[32/200] loss:0.2169 acc:0.9434\n",
      "INFO:root:========= Testing: epoch[33/200] loss:0.2188 acc:0.9465\n",
      "INFO:root:========= Testing: epoch[34/200] loss:0.2257 acc:0.9430\n",
      "INFO:root:========= Testing: epoch[35/200] loss:0.2140 acc:0.9443\n",
      "INFO:root:========= Testing: epoch[36/200] loss:0.2106 acc:0.9437\n",
      "INFO:root:========= Testing: epoch[37/200] loss:0.2151 acc:0.9449\n",
      "INFO:root:========= Testing: epoch[38/200] loss:0.2209 acc:0.9449\n",
      "INFO:root:========= Testing: epoch[39/200] loss:0.2174 acc:0.9453\n",
      "INFO:root:========= Testing: epoch[40/200] loss:0.2177 acc:0.9451\n",
      "INFO:root:========= Testing: epoch[41/200] loss:0.2094 acc:0.9486\n",
      "INFO:root:========= Testing: epoch[42/200] loss:0.2032 acc:0.9502\n",
      "INFO:root:========= Testing: epoch[43/200] loss:0.2087 acc:0.9459\n",
      "INFO:root:========= Testing: epoch[44/200] loss:0.2071 acc:0.9445\n",
      "INFO:root:========= Testing: epoch[45/200] loss:0.2085 acc:0.9486\n",
      "INFO:root:========= Testing: epoch[46/200] loss:0.2107 acc:0.9436\n",
      "INFO:root:========= Testing: epoch[47/200] loss:0.2136 acc:0.9457\n",
      "INFO:root:========= Testing: epoch[48/200] loss:0.2136 acc:0.9445\n",
      "INFO:root:========= Testing: epoch[49/200] loss:0.2148 acc:0.9467\n",
      "INFO:root:========= Testing: epoch[50/200] loss:0.2246 acc:0.9426\n",
      "INFO:root:========= Testing: epoch[51/200] loss:0.2089 acc:0.9465\n",
      "INFO:root:========= Testing: epoch[52/200] loss:0.2149 acc:0.9469\n",
      "INFO:root:========= Testing: epoch[53/200] loss:0.2011 acc:0.9498\n",
      "INFO:root:========= Testing: epoch[54/200] loss:0.2133 acc:0.9492\n",
      "INFO:root:========= Testing: epoch[55/200] loss:0.2122 acc:0.9525\n",
      "INFO:root:========= Testing: epoch[56/200] loss:0.2166 acc:0.9496\n",
      "INFO:root:========= Testing: epoch[57/200] loss:0.2026 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[58/200] loss:0.2205 acc:0.9490\n",
      "INFO:root:========= Testing: epoch[59/200] loss:0.2156 acc:0.9447\n",
      "INFO:root:========= Testing: epoch[60/200] loss:0.2052 acc:0.9514\n",
      "INFO:root:========= Testing: epoch[61/200] loss:0.2146 acc:0.9514\n",
      "INFO:root:========= Testing: epoch[62/200] loss:0.2019 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[63/200] loss:0.2170 acc:0.9512\n",
      "INFO:root:========= Testing: epoch[64/200] loss:0.2180 acc:0.9471\n",
      "INFO:root:========= Testing: epoch[65/200] loss:0.2144 acc:0.9451\n",
      "INFO:root:========= Testing: epoch[66/200] loss:0.2162 acc:0.9455\n",
      "INFO:root:========= Testing: epoch[67/200] loss:0.2239 acc:0.9424\n",
      "INFO:root:========= Testing: epoch[68/200] loss:0.2055 acc:0.9494\n",
      "INFO:root:========= Testing: epoch[69/200] loss:0.2123 acc:0.9453\n",
      "INFO:root:========= Testing: epoch[70/200] loss:0.2186 acc:0.9467\n",
      "INFO:root:========= Testing: epoch[71/200] loss:0.2062 acc:0.9496\n",
      "INFO:root:========= Testing: epoch[72/200] loss:0.2087 acc:0.9486\n",
      "INFO:root:========= Testing: epoch[73/200] loss:0.2006 acc:0.9525\n",
      "INFO:root:========= Testing: epoch[74/200] loss:0.2114 acc:0.9461\n",
      "INFO:root:========= Testing: epoch[75/200] loss:0.2155 acc:0.9488\n",
      "INFO:root:========= Testing: epoch[76/200] loss:0.2074 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[77/200] loss:0.2175 acc:0.9506\n",
      "INFO:root:========= Testing: epoch[78/200] loss:0.2186 acc:0.9465\n",
      "INFO:root:========= Testing: epoch[79/200] loss:0.2165 acc:0.9488\n",
      "INFO:root:========= Testing: epoch[80/200] loss:0.2137 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[81/200] loss:0.2082 acc:0.9447\n",
      "INFO:root:========= Testing: epoch[82/200] loss:0.1973 acc:0.9490\n",
      "INFO:root:========= Testing: epoch[83/200] loss:0.2159 acc:0.9486\n",
      "INFO:root:========= Testing: epoch[84/200] loss:0.2111 acc:0.9508\n",
      "INFO:root:========= Testing: epoch[85/200] loss:0.1975 acc:0.9510\n",
      "INFO:root:========= Testing: epoch[86/200] loss:0.2062 acc:0.9502\n",
      "INFO:root:========= Testing: epoch[87/200] loss:0.2081 acc:0.9512\n",
      "INFO:root:========= Testing: epoch[88/200] loss:0.2018 acc:0.9492\n",
      "INFO:root:========= Testing: epoch[89/200] loss:0.2060 acc:0.9496\n",
      "INFO:root:========= Testing: epoch[90/200] loss:0.2022 acc:0.9525\n",
      "INFO:root:========= Testing: epoch[91/200] loss:0.2007 acc:0.9539\n",
      "INFO:root:========= Testing: epoch[92/200] loss:0.2198 acc:0.9480\n",
      "INFO:root:========= Testing: epoch[93/200] loss:0.1947 acc:0.9535\n",
      "INFO:root:========= Testing: epoch[94/200] loss:0.2179 acc:0.9477\n",
      "INFO:root:========= Testing: epoch[95/200] loss:0.2009 acc:0.9504\n",
      "INFO:root:========= Testing: epoch[96/200] loss:0.2115 acc:0.9471\n",
      "INFO:root:========= Testing: epoch[97/200] loss:0.2113 acc:0.9471\n",
      "INFO:root:========= Testing: epoch[98/200] loss:0.2065 acc:0.9514\n",
      "INFO:root:========= Testing: epoch[99/200] loss:0.2022 acc:0.9525\n",
      "INFO:root:========= Testing: epoch[100/200] loss:0.2024 acc:0.9496\n",
      "INFO:root:========= Testing: epoch[101/200] loss:0.2125 acc:0.9502\n",
      "INFO:root:========= Testing: epoch[102/200] loss:0.2131 acc:0.9527\n",
      "INFO:root:========= Testing: epoch[103/200] loss:0.2029 acc:0.9514\n",
      "INFO:root:========= Testing: epoch[104/200] loss:0.2123 acc:0.9508\n",
      "INFO:root:========= Testing: epoch[105/200] loss:0.2066 acc:0.9490\n",
      "INFO:root:========= Testing: epoch[106/200] loss:0.2135 acc:0.9529\n",
      "INFO:root:========= Testing: epoch[107/200] loss:0.2428 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[108/200] loss:0.2201 acc:0.9520\n",
      "INFO:root:========= Testing: epoch[109/200] loss:0.2007 acc:0.9486\n",
      "INFO:root:========= Testing: epoch[110/200] loss:0.2029 acc:0.9467\n",
      "INFO:root:========= Testing: epoch[111/200] loss:0.2104 acc:0.9496\n",
      "INFO:root:========= Testing: epoch[112/200] loss:0.2181 acc:0.9531\n",
      "INFO:root:========= Testing: epoch[113/200] loss:0.2198 acc:0.9488\n",
      "INFO:root:========= Testing: epoch[114/200] loss:0.2005 acc:0.9512\n",
      "INFO:root:========= Testing: epoch[115/200] loss:0.2028 acc:0.9520\n",
      "INFO:root:========= Testing: epoch[116/200] loss:0.1997 acc:0.9516\n",
      "INFO:root:========= Testing: epoch[117/200] loss:0.2122 acc:0.9535\n",
      "INFO:root:========= Testing: epoch[118/200] loss:0.2036 acc:0.9537\n",
      "INFO:root:========= Testing: epoch[119/200] loss:0.2019 acc:0.9527\n",
      "INFO:root:========= Testing: epoch[120/200] loss:0.2223 acc:0.9520\n",
      "INFO:root:========= Testing: epoch[121/200] loss:0.2027 acc:0.9484\n",
      "INFO:root:========= Testing: epoch[122/200] loss:0.2074 acc:0.9510\n",
      "INFO:root:========= Testing: epoch[123/200] loss:0.2119 acc:0.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:========= Testing: epoch[124/200] loss:0.2074 acc:0.9521\n",
      "INFO:root:========= Testing: epoch[125/200] loss:0.2055 acc:0.9523\n",
      "INFO:root:========= Testing: epoch[126/200] loss:0.2256 acc:0.9498\n",
      "INFO:root:========= Testing: epoch[127/200] loss:0.2099 acc:0.9484\n",
      "INFO:root:========= Testing: epoch[128/200] loss:0.2050 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[129/200] loss:0.1984 acc:0.9543\n",
      "INFO:root:========= Testing: epoch[130/200] loss:0.2145 acc:0.9475\n",
      "INFO:root:========= Testing: epoch[131/200] loss:0.2012 acc:0.9504\n",
      "INFO:root:========= Testing: epoch[132/200] loss:0.2076 acc:0.9480\n",
      "INFO:root:========= Testing: epoch[133/200] loss:0.2076 acc:0.9502\n",
      "INFO:root:========= Testing: epoch[134/200] loss:0.2076 acc:0.9516\n",
      "INFO:root:========= Testing: epoch[135/200] loss:0.2189 acc:0.9514\n",
      "INFO:root:========= Testing: epoch[136/200] loss:0.2183 acc:0.9500\n",
      "INFO:root:========= Testing: epoch[137/200] loss:0.2072 acc:0.9508\n",
      "INFO:root:========= Testing: epoch[138/200] loss:0.2141 acc:0.9516\n",
      "INFO:root:========= Testing: epoch[139/200] loss:0.2124 acc:0.9496\n",
      "INFO:root:========= Testing: epoch[140/200] loss:0.1986 acc:0.9553\n",
      "INFO:root:========= Testing: epoch[141/200] loss:0.2119 acc:0.9520\n",
      "INFO:root:========= Testing: epoch[142/200] loss:0.2217 acc:0.9502\n",
      "INFO:root:========= Testing: epoch[143/200] loss:0.2182 acc:0.9508\n",
      "INFO:root:========= Testing: epoch[144/200] loss:0.2145 acc:0.9535\n",
      "INFO:root:========= Testing: epoch[145/200] loss:0.2069 acc:0.9486\n",
      "INFO:root:========= Testing: epoch[146/200] loss:0.2209 acc:0.9520\n",
      "INFO:root:========= Testing: epoch[147/200] loss:0.2116 acc:0.9467\n",
      "INFO:root:========= Testing: epoch[148/200] loss:0.2180 acc:0.9506\n",
      "INFO:root:========= Testing: epoch[149/200] loss:0.2090 acc:0.9521\n",
      "INFO:root:========= Testing: epoch[150/200] loss:0.2062 acc:0.9531\n",
      "INFO:root:========= Testing: epoch[151/200] loss:0.2282 acc:0.9529\n",
      "INFO:root:========= Testing: epoch[152/200] loss:0.2120 acc:0.9537\n",
      "INFO:root:========= Testing: epoch[153/200] loss:0.2146 acc:0.9518\n",
      "INFO:root:========= Testing: epoch[154/200] loss:0.2098 acc:0.9543\n",
      "INFO:root:========= Testing: epoch[155/200] loss:0.2107 acc:0.9508\n",
      "INFO:root:========= Testing: epoch[156/200] loss:0.2263 acc:0.9480\n",
      "INFO:root:========= Testing: epoch[157/200] loss:0.2099 acc:0.9523\n",
      "INFO:root:========= Testing: epoch[158/200] loss:0.2073 acc:0.9508\n",
      "INFO:root:========= Testing: epoch[159/200] loss:0.2120 acc:0.9463\n",
      "INFO:root:========= Testing: epoch[160/200] loss:0.1983 acc:0.9529\n",
      "INFO:root:========= Testing: epoch[161/200] loss:0.2129 acc:0.9520\n",
      "INFO:root:========= Testing: epoch[162/200] loss:0.2271 acc:0.9459\n",
      "INFO:root:========= Testing: epoch[163/200] loss:0.2054 acc:0.9529\n",
      "INFO:root:========= Testing: epoch[164/200] loss:0.2143 acc:0.9535\n",
      "INFO:root:========= Testing: epoch[165/200] loss:0.2222 acc:0.9475\n",
      "INFO:root:========= Testing: epoch[166/200] loss:0.2163 acc:0.9502\n",
      "INFO:root:========= Testing: epoch[167/200] loss:0.2293 acc:0.9465\n",
      "INFO:root:========= Testing: epoch[168/200] loss:0.2375 acc:0.9469\n",
      "INFO:root:========= Testing: epoch[169/200] loss:0.2065 acc:0.9500\n"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(cfg.epoch):\n",
    "    # ========================== Training Model =============================\n",
    "    net.train()\n",
    "#     for batch_idx in range(len(train_x)):\n",
    "    for batch_idx, (train_img, train_target) in enumerate(train_loader):\n",
    "#         train_img = Variable(train_x[batch_idx])\n",
    "#         train_target = Variable(train_y[batch_idx])\n",
    "        train_img = Variable(train_img)\n",
    "        train_target = Variable(train_target)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            train_img = train_img.cuda(cfg.cuda_num)\n",
    "            train_target = train_target.cuda(cfg.cuda_num)\n",
    "\n",
    "        _, predict = net(train_img)\n",
    "\n",
    "        loss = loss_func(predict, train_target)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        acc = calc_acc(predict.cpu().data, train_target.cpu().data)\n",
    "        \n",
    "        # if batch_idx % cfg.show_train_result_every_batch == 0:\n",
    "        #     logging.info('epoch[%d/%d] batch[%d/%d] loss:%.4f acc:%.4f'\n",
    "        #                  % (epoch_idx, cfg.epoch, batch_idx, train_batch_nb, loss.data[0], acc))\n",
    "\n",
    "#     # ========================== Testing Model =============================\n",
    "    if (epoch_idx + 1) % cfg.test_every_epoch == 0:\n",
    "        net.eval()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "#         for batch_idx in range(len(test_x)):\n",
    "        for batch_idx, (test_img, test_target) in enumerate(test_loader):\n",
    "            batch_size = test_img.size(0)\n",
    "\n",
    "            test_img = Variable(test_img, volatile=True)\n",
    "            test_target = Variable(test_target, volatile=True)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                test_img = test_img.cuda(cfg.cuda_num)\n",
    "                test_target = test_target.cuda(cfg.cuda_num)\n",
    "\n",
    "            transform_img, predict = net(test_img)\n",
    "\n",
    "            loss = loss_func(predict, test_target)\n",
    "            acc = calc_acc(predict.cpu().data, test_target.cpu().data)\n",
    "\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            if cfg.mode == 'stn':\n",
    "                img_list = []\n",
    "                for idx in range(batch_size):\n",
    "                    img_list.append(test_img[idx])\n",
    "                    img_list.append(transform_img[idx])\n",
    "                output_img = torch.stack(img_list)\n",
    "\n",
    "                vutils.save_image(output_img.data, os.path.join(cfg.transform_img_dir, '%d.png' % batch_idx),\n",
    "                                  nrow=20)\n",
    "\n",
    "        mean_loss = total_loss / test_batch_nb\n",
    "        mean_acc = total_acc / test_batch_nb\n",
    "        logging.info('========= Testing: epoch[%d/%d] loss:%.4f acc:%.4f' % (epoch_idx, cfg.epoch, mean_loss.data[0], mean_acc))\n",
    "\n",
    "    if (epoch_idx + 1) % cfg.save_model_every_epoch == 0:\n",
    "        state_dict = net.state_dict()\n",
    "        torch.save(state_dict, os.path.join(cfg.model_dir, cfg.model_name % cfg.mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
